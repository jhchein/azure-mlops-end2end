{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create Synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1696442542547
        }
      },
      "outputs": [],
      "source": [
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "# Establish a connection to the workspace\n",
        "ml_client = MLClient.from_config(DefaultAzureCredential())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Existing Data\n",
        "Load the existing diabetes data to understand its structure before generating synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1696442553540
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import mltable\n",
        "\n",
        "# Load the existing data asset\n",
        "data_asset = ml_client.data.get(\"diabetes-mltable-production\", label=\"latest\")\n",
        "\n",
        "# Convert the data asset to a Pandas DataFrame\n",
        "tbl = mltable.load(data_asset.path)\n",
        "diabetes = tbl.to_pandas_dataframe()\n",
        "diabetes.head()  # Display the first few rows to understand the data structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Generate Synthetic Data\n",
        "\n",
        "Create a synthetic dataset mimicking the structure and statistical properties of the original diabetes dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1696442624807
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Create a synthetic dataset with the same shape as the original dataset\n",
        "num_rows = diabetes.shape[0]\n",
        "synthetic_data = pd.DataFrame()\n",
        "\n",
        "# Generate PatientID - unique 7-digit numbers\n",
        "synthetic_data['PatientID'] = np.random.choice(range(1000000, 9999999), num_rows, replace=False)\n",
        "\n",
        "# Generate Pregnancies - assuming a range of 0 to 17 pregnancies\n",
        "synthetic_data['Pregnancies'] = np.random.randint(0, 18, num_rows)\n",
        "\n",
        "# Generate PlasmaGlucose - assuming a mean of 120 and std deviation of 20\n",
        "synthetic_data['PlasmaGlucose'] = np.random.normal(120, 20, num_rows).astype(int)\n",
        "\n",
        "# Generate DiastolicBloodPressure - assuming a mean of 80 and std deviation of 10\n",
        "synthetic_data['DiastolicBloodPressure'] = np.random.normal(80, 10, num_rows).astype(int)\n",
        "\n",
        "# Generate TricepsThickness - assuming a mean of 25 and std deviation of 10\n",
        "synthetic_data['TricepsThickness'] = np.random.normal(25, 10, num_rows).astype(int)\n",
        "\n",
        "# Generate SerumInsulin - assuming a mean of 140 and std deviation of 85\n",
        "synthetic_data['SerumInsulin'] = np.random.normal(140, 85, num_rows).astype(int)\n",
        "\n",
        "# Generate BMI - assuming a mean of 30 and std deviation of 5\n",
        "synthetic_data['BMI'] = np.random.normal(30, 5, num_rows)\n",
        "\n",
        "# Generate DiabetesPedigree - assuming a mean of 0.5 and std deviation of 0.3\n",
        "synthetic_data['DiabetesPedigree'] = np.random.normal(0.5, 0.3, num_rows)\n",
        "\n",
        "# Generate Age - assuming a mean of 30 and std deviation of 10\n",
        "synthetic_data['Age'] = np.random.normal(30, 10, num_rows).astype(int)\n",
        "\n",
        "# Save the synthetic dataset to disk\n",
        "os.makedirs(\"data/synthetic-diabetes-data/\", exist_ok=True)\n",
        "synthetic_data.to_csv(\"data/synthetic-diabetes-data/synthetic.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "gather": {
          "logged": 1696442626911
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Convert to MLTable and Save\n",
        "\n",
        "Convert the synthetic dataset to an mltable object and save it to disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1696442690727
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "tbl_synthetic = mltable.from_delimited_files(paths=[{\"pattern\": \"data/synthetic-diabetes-data/synthetic.csv\"}])\n",
        "tbl_synthetic.save(\"data/synthetic-diabetes-data\")\n",
        "tbl_synthetic.show(5)  # Display the first few rows of the synthetic data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Optional) Register Synthetic Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1696442849564
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# import time\n",
        "# from azure.ai.ml.entities import Data\n",
        "# from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "# # Set the version number of the data asset to the current UTC time\n",
        "# VERSION = time.strftime(\"%Y.%m.%d.%H%M%S\", time.gmtime())\n",
        "\n",
        "# my_data_synthetic = Data(\n",
        "#     path=\"./data/synthetic-diabetes-data\",\n",
        "#     type=AssetTypes.MLTABLE,\n",
        "#     description=\"Synthetic data for the diabetes dataset\",\n",
        "#     name=\"diabetes-mltable-synthetic\",\n",
        "#     version=VERSION,\n",
        "# )\n",
        "\n",
        "# ml_client.data.create_or_update(my_data_synthetic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Invoke the Endpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialize the variables with your endpoint name, deployment name, and API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "online_endpoint_name = \"<your_endpoint_name>\"\n",
        "deployment = \"<your_deployment_name>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.invoke import invoke_endpoint\n",
        "\n",
        "# Get the details for online endpoint\n",
        "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
        "\n",
        "api_key = ml_client.online_endpoints.get_keys(online_endpoint_name).primary_key\n",
        "\n",
        "# Display existing traffic details\n",
        "print(f\"Traffic Details: {endpoint.traffic}\")\n",
        "\n",
        "# Display the scoring URI\n",
        "print(f\"Scoring URI: {endpoint.scoring_uri}\")\n",
        "\n",
        "url = endpoint.scoring_uri"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remember, we can load the MLTable as a pandas dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_asset = ml_client.data.get(\"diabetes-mltable-synthetic\", label=\"latest\")\n",
        "\n",
        "# Load the table and convert to Pandas DataFrame\n",
        "tbl = mltable.load(data_asset.path)\n",
        "df = tbl.to_pandas_dataframe()\n",
        "df.head()  # Display the first few rows of the DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare the Synthetic data by separating the features (X) and the target variable (y), then split the data into batches for batch processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Separate features and target variable\n",
        "X, y = df[['Pregnancies', 'PlasmaGlucose', 'DiastolicBloodPressure', 'TricepsThickness', 'SerumInsulin', 'BMI', 'DiabetesPedigree', 'Age']], df['Diabetic']\n",
        "\n",
        "# Split the DataFrame into batches of size 5\n",
        "batches = [batch.values.tolist() for batch in np.array_split(X, len(X) / 5)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Invoke the endpoint with each batch of data to get predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = []\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "for batch in tqdm(batches):\n",
        "    payload = {\"input_data\": batch, \"params\": {}}\n",
        "    predictions_batch = invoke_endpoint(url, deployment, api_key, payload)\n",
        "    predictions.extend(predictions_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explore Collected Data from Production\n",
        "\n",
        "### Load and Explore Data\n",
        "\n",
        "Last but not least, we'll load the data assets, convert them to Pandas DataFrames, and inspect the last record of each dataset to understand the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mltable\n",
        "\n",
        "def load_and_inspect_data(asset_name, version):\n",
        "    # Get the data asset\n",
        "    data_asset = ml_client.data.get(asset_name, version=version)\n",
        "    \n",
        "    # Define the path to the data asset\n",
        "    path = {'folder': data_asset.path}\n",
        "    \n",
        "    # Load the data as an mltable object\n",
        "    tbl = mltable.from_json_lines_files(paths=[path])\n",
        "    \n",
        "    # Convert the mltable to a Pandas DataFrame\n",
        "    df = tbl.to_pandas_dataframe()\n",
        "    \n",
        "    # Inspect the last record of the DataFrame\n",
        "    last_record = df.iloc[-1]\n",
        "    print(f'Last record of {asset_name}:\\n{last_record}\\n')\n",
        "\n",
        "# Base string for the deployment name\n",
        "deployment_base_name = \"<deployment-name>\" # Replace with your deployment name\n",
        "\n",
        "# Construct asset names dynamically based on the deployment name\n",
        "asset_info = [\n",
        "    (f\"{deployment_base_name}-model_outputs\", \"1\"),\n",
        "    (f\"{deployment_base_name}-model_inputs_outputs\", \"1\"),\n",
        "    (f\"{deployment_base_name}-model_inputs\", \"1\")\n",
        "]\n",
        "\n",
        "# Load and inspect each data asset\n",
        "for asset_name, version in asset_info:\n",
        "    load_and_inspect_data(asset_name, version)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next step\n",
        "\n",
        "Congratulations, we have developed and understood the basics how to\n",
        "- train \n",
        "- deploy\n",
        "- invoke\n",
        "- monitor\n",
        "\n",
        "a machine learning model.\n",
        "\n",
        "Now we head towards automation. The `CLI` README section of this repository will guide our next steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
