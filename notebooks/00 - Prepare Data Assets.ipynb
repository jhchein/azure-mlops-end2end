{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Diabetes Dataset Preparation Notebook\n",
        "\n",
        "This notebook serves as the first step in a series of notebooks aimed at analyzing a diabetes dataset. In this notebook, we'll focus on data acquisition, sampling, and preparation for model training in subsequent steps. The key processes include:\n",
        "\n",
        "1. **Environment Setup**:\n",
        "    - Importing necessary libraries.\n",
        "    - Establishing Azure ML client connection.\n",
        "\n",
        "2. **Data Acquisition**:\n",
        "    - Defining the data paths.\n",
        "    - Loading data into `MLTable` objects using `mltable.from_delimited_files()`.\n",
        "\n",
        "3. **Data Sampling**:\n",
        "    - Random sampling of data using `mltable` functionality.\n",
        "    - Converting sampled data to Pandas DataFrame for further analysis.\n",
        "\n",
        "4. **Data Saving and Versioning**:\n",
        "    - Saving the data to disk in MLTable format.\n",
        "    - Creating or updating the data asset in Azure ML with versioning.\n",
        "\n",
        "5. **Data Splitting**:\n",
        "    - Splitting the data into training and testing sets using `train_test_split`.\n",
        "    - Exploring the split data (optional).\n",
        "\n",
        "6. **Data Persistence**:\n",
        "    - Saving the split data to disk for future use.\n",
        "\n",
        "This notebook sets the stage for the following notebooks in this series:\n",
        "- **Train and Deploy a Model**: Building, training, and deploying a machine learning model.\n",
        "- **Invoke a Real-Time Endpoint**: Making real-time predictions using the deployed model.\n",
        "- **Create Synthetic Data**: Generating synthetic data for further analysis.\n",
        "- **Explore Collected Data from Production**: Analyzing data collected from the production environment to gain insights and improve the model.\n",
        "\n",
        "**Note**: This notebook assumes familiarity with Azure ML, Scikit-learn, and the `mltable` library for tabular data manipulation and analysis. For more detailed information on `mltable`, please refer to the [official documentation](link_to_mltable_documentation).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697218725674
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# !pip install mltable scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697218727685
        }
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import mltable\n",
        "import os\n",
        "import time\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.identity import DefaultAzureCredential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n",
        "\n",
        "In this section, we'll load the diabetes dataset from two distinct files using `mltable.from_delimited_files()`. \n",
        "\n",
        "The paths variable holds dictionaries that specify the URLs of these CSV files. Allowed keys are `file`, `folder`, and `pattern`. For demonstration purposes we use both pattern and file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697218729085
        }
      },
      "outputs": [],
      "source": [
        "paths = [\n",
        "    {\n",
        "        \"pattern\": \"https://raw.githubusercontent.com/MicrosoftLearning/mslearn-dp100/main/data/diabetes.csv\"\n",
        "    },\n",
        "    {\n",
        "        \"file\": \"https://raw.githubusercontent.com/MicrosoftLearning/mslearn-dp100/main/data/diabetes2.csv\"\n",
        "    },\n",
        "    # {\n",
        "    #     \"folder\": \"https://raw.githubusercontent.com/MicrosoftLearning/mslearn-dp100/main/data/\"\n",
        "    # }\n",
        "]\n",
        "\n",
        "# Create an MLTable object\n",
        "tbl = mltable.from_delimited_files(paths)\n",
        "\n",
        "# tbl.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `mltable.from_delimited_files()` function simplifies the loading process by auto-detecting the delimiter and establishing appropriate column names and data types, encapsulating the data within an MLTable object for easy manipulation and analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample Data\n",
        "For initial exploration and model testing, we could also draw a random sample from the loaded data. The `tbl.take_random_sample()` method facilitates this, where `probability` sets the row selection chance, and `seed` ensures reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697218729517
        }
      },
      "outputs": [],
      "source": [
        "# Take a random sample of the table\n",
        "tbl_sample = tbl.take_random_sample(probability=0.001, seed=735)\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "df = tbl_sample.to_pandas_dataframe()\n",
        "\n",
        "# Display the first few rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our data contains a `PatientID` (as patients can visit the doctor multiple times, this ID is not unique per row), several features and the label `Diabetic` which is to be predicted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Production data\n",
        "\n",
        "To simulate ML OPs we will need `production` data, that will be used for model inference on the training model. Therefore, we'll split our data historically (by increasing `patientID`) and we'll keep the later samples / higher PatientID out of our dataset (for a `production` sample)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697218729834
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "median_patient_id = str(int(df[\"PatientID\"].median()))\n",
        "median_patient_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The built-in mltables filters make this really easy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697218730145
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# tbl_sample.random_split(percent=.5)\n",
        "tbl_dev = tbl.filter(f'PatientID <= {median_patient_id}')\n",
        "tbl_prod = tbl.filter(f'PatientID > {median_patient_id}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Enriching Production Data with Dates\n",
        "\n",
        "We split features and labels and thereby drop the patientID, as it contains no useful information for our model (other that it could memorize IDs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697221160813
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "tbl_prod_features, tbl_prod_labels = tbl_prod.drop_columns([\"Diabetic\", \"PatientID\"]), tbl_prod.keep_columns([\"Diabetic\"])\n",
        "tbl_prod_features.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tbl_prod_labels.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To simulate `production` data, we create a `date` column and enrich it with artificial dates hovering around now plus/minus 30 days. \n",
        "\n",
        "We thereby have ~half of the data available for instant inference and simulate continuos inference over the next month."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697221328832
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Assuming df is your DataFrame\n",
        "df_prod_features = tbl_prod_features.to_pandas_dataframe()\n",
        "\n",
        "# Get today's date\n",
        "today = datetime.today()\n",
        "\n",
        "# Generate random number of days between -30 and 30\n",
        "random_days = np.random.randint(-30, 30, size=len(df_prod_features))\n",
        "\n",
        "# Create date column with random dates\n",
        "df_prod_features['date'] = [(today + timedelta(days=int(d))).isoformat() + 'Z' for d in random_days]\n",
        "\n",
        "df_prod_features.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Saving and Versioning\n",
        "\n",
        "Now that we have everything (training data and enriched production data), we can create AzureML data assets. \n",
        "\n",
        "We therefore define an asset version based on the current UTC time. This versioning can be invaluable for traceability and managing data versions in machine learning workflows.\n",
        "\n",
        "For our training data (`tbl_dev`), due to it's relational format, MLTable is the best format to use.\n",
        "\n",
        "In contrast, we need to store the production data as a URI_FOLDER or order to be processed by our Data and Model Monitor (which leverages Spark)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697218730355
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Set the version number of the data asset to the current UTC time\n",
        "VERSION = time.strftime(\"%Y.%m.%d.%H%M%S\", time.gmtime())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697218730674
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# delete data directory if it exists\n",
        "import shutil\n",
        "if os.path.exists(\"data\"):\n",
        "    shutil.rmtree(\"data\")\n",
        "\n",
        "# Create the data directory and subdirectories for train, test, eval, and prod data\n",
        "os.makedirs(\"data\")\n",
        "os.makedirs(\"data/train\")\n",
        "os.makedirs(\"data/prod\")\n",
        "os.makedirs(\"data/prod/features\")\n",
        "os.makedirs(\"data/prod/labels\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Connect to the AzureML workspace and define the `URI_FOLDER` data asset for `production` data (only the features). The `create_or_update` method is employed to either create a new data asset or update an existing one in AzureML."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697221473785
        }
      },
      "outputs": [],
      "source": [
        "df_prod_features.to_parquet(\"./data/prod/features/data.parquet\")\n",
        "\n",
        "# Connect to the AzureML workspace\n",
        "ml_client = MLClient.from_config(credential=DefaultAzureCredential())\n",
        "\n",
        "# Define the data asset\n",
        "production_inputs = Data(\n",
        "    path=\"./data/prod/features\",\n",
        "    type=AssetTypes.URI_FOLDER,\n",
        "    description=\"Example data from the diabetes dataset (Production)\",\n",
        "    name=\"diabetes-urifolder-production\",\n",
        "    version=VERSION,\n",
        ")\n",
        "\n",
        "# Create or update the data asset in AzureML\n",
        "ml_client.data.create_or_update(production_inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697218735913
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Define the data asset\n",
        "tbl_prod_labels.save(\"./data/prod/labels\")\n",
        "\n",
        "production_labels = Data(\n",
        "    path=\"./data/prod/labels\",\n",
        "    type=AssetTypes.MLTABLE,\n",
        "    description=\"Example data from the diabetes dataset (Production Labels)\",\n",
        "    name=\"diabetes-mltable-production-labels\",\n",
        "    version=VERSION,\n",
        ")\n",
        "\n",
        "# Create or update the data asset in AzureML\n",
        "ml_client.data.create_or_update(production_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tbl_dev.save(\"./data/dev\")\n",
        "\n",
        "# Define the data asset\n",
        "training_data = Data(\n",
        "    path=\"./data/dev/\",\n",
        "    type=AssetTypes.MLTABLE,\n",
        "    description=\"Example data from the diabetes dataset (Train, Test, Eval)\",\n",
        "    name=\"diabetes-mltable-dev\",\n",
        "    version=VERSION,\n",
        ")\n",
        "\n",
        "# Create or update the data asset in AzureML\n",
        "ml_client.data.create_or_update(training_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next step\n",
        "\n",
        "We've created some data assets, that lay the foundation of this accelerator. Proceed with the next notebook to understand how to train and deploy Models in AzureML."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
