{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train and deploy a model\n",
        "\n",
        "> [!NOTE] Must use Python 3.10 SDK V2 for this demo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train a model\n",
        "\n",
        "Initiate a connection to the Azure ML workspace and set up MLflow for tracking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697218927660
        }
      },
      "outputs": [],
      "source": [
        "## Train a model\n",
        "\n",
        "# Handle to the workspace\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml import MLClient\n",
        "import mlflow\n",
        "\n",
        "ml_client = MLClient.from_config(\n",
        "    DefaultAzureCredential()\n",
        ")\n",
        "\n",
        "# Gather MLflow URI information from workspace\n",
        "azureml_mlflow_uri = ml_client.workspaces.get(ml_client.workspace_name).mlflow_tracking_uri\n",
        "mlflow.set_tracking_uri(azureml_mlflow_uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import necessary libraries and set up the experiment in MLflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697218929573
        }
      },
      "outputs": [],
      "source": [
        "# Import python packages\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "experiment_name = \"Monitoring-Models-Experiment\"\n",
        "mlflow.set_experiment(experiment_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the dataset, convert it to a Pandas DataFrame, and prepare the directory for model saving."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697218932478
        }
      },
      "outputs": [],
      "source": [
        "import mltable\n",
        "\n",
        "# iterate over all versions of the data asset\n",
        "\n",
        "data_asset = ml_client.data.get(\"diabetes-mltable-dev\", label=\"latest\")\n",
        "\n",
        "tbl = mltable.load(data_asset.path)\n",
        "\n",
        "df = tbl.to_pandas_dataframe()\n",
        "df\n",
        "\n",
        "model_path = \"./models/monitoring\"\n",
        "os.makedirs(model_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Start logging the training process in MLflow, train a Decision Tree model, and log the model performance metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697218934111
        }
      },
      "outputs": [],
      "source": [
        "# delete model directory if it exists\n",
        "import shutil\n",
        "if os.path.exists(model_path):\n",
        "    shutil.rmtree(model_path)\n",
        "\n",
        "# Start Logging\n",
        "mlflow.start_run()\n",
        "\n",
        "# Enable autologging (optional)\n",
        "# mlflow.sklearn.autolog()\n",
        "\n",
        "diabetes = df\n",
        "\n",
        "# Breaking up data into input/target features\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Breaking data into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Training a model:\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "# Calculating performance and logging them\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "mlflow.log_metric('Accuracy', float(acc))\n",
        "\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "mlflow.log_metric('AUC', float(auc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Infer the model signature, register the model to the workspace, and save the model to a file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1697218945451
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from mlflow.models import infer_signature\n",
        "\n",
        "signature = infer_signature(X_test, y_hat)\n",
        "\n",
        "# Registering the model to the workspace\n",
        "print(\"Registering the model via MLFlow\")\n",
        "mlflow.sklearn.log_model(\n",
        "    sk_model=model,\n",
        "    registered_model_name=\"monitoring-diabetes\",\n",
        "    artifact_path=\"model\",\n",
        "    signature=signature,\n",
        ")\n",
        "\n",
        "# Saving the model to a file\n",
        "mlflow.sklearn.save_model(\n",
        "    sk_model=model, \n",
        "    path=model_path,\n",
        "    signature=signature\n",
        ")\n",
        "\n",
        "# Stop logging\n",
        "mlflow.end_run()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deploy a Model\n",
        "\n",
        "After training and registering the model, it's time to deploy it. The easiest and most explaining way is to use the AzureML Studio UI.\n",
        "\n",
        "Under `Models` select the recently trained model and select `Deploy` as a `Real time endpoint`. \n",
        "\n",
        "- This action will create a new Deployment on a new or existing endpoint (as you can deploy multiple models behind one endpoint).\n",
        "- Keep the instances at 3 instances, so that we can add autoscaling later.\n",
        "- Make sure to enable data collection (still in preview as of Nov '23).\n",
        "\n",
        "The deployment will take a few minutes, make sure to grab a cup of coffee. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explore the endpoint\n",
        "\n",
        "Once the deploymet is complete go to `Endpoints`, select the newly deployed endpoint, and then select `Test`. \n",
        "\n",
        "The data should be pre-populated. If for some reason it is not, use this JSON Data\n",
        "```JSON\n",
        "[11.0, 97.0, 89.0, 11.0, 23.0, 46.47006691, 1.476670289, 39.0],\n",
        "[3.0, 108.0, 63.0, 45.0, 297.0, 49.37516891, 0.100979095, 46.0],\n",
        "[9, 103, 78, 25, 304, 29.58219193, 1.282869847, 43]\n",
        "```\n",
        "or `notebooks/test.json` for scoring."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Collection\n",
        "\n",
        "Now after having scored some samples, head to `Data` within the Studio. You'll now find a few more datasets such as `<endpointname>-inputs` and `<endpointname>-outputs`. Explore the data that is automatically collected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Monitoring the Endpoint\n",
        "\n",
        "Finally go back to the `Endpoint`, scroll to the bottom and select `View metrics`. This will lead you to the `Azure Application Insights` instance that logs your workspace. \n",
        "\n",
        "Explore the metrics logged in your `Application Insights`. \n",
        "\n",
        "Be aware, some metrics and logs are only collected after you enabled `Diagnostic settings`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Monitoring your dataset and model drift\n",
        "\n",
        "Azure ML recently added the preview of Model and Data monitoring. We can now leverage this powerful feature via `Monitoring` in the AzureML Studio.\n",
        "\n",
        "Add a new monitor via `+ Add` and follow the wizard. \n",
        "- Select the model we trained and the deployment we just created.\n",
        "- Under `Configure data assets` add the training data we registered in the first notbook.\n",
        "- Under `Select monitoring signals` make sure to hit edit one of the signal by selecting `Diabetic` as the target column.\n",
        "\n",
        "Create the monitor, grab another coffee, and chat about your learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Optional) Monitoring Drift: Bring your own data\n",
        "\n",
        "If you are keen on exploring **how to bring your own production data** (that is not collected from an online endpoint) now is your time to understand how that works.\n",
        "\n",
        "Remember, we registered a `diabetes-urifolder-production` dataset in the first notebook. This repository also contains a `preprocess component` (in the `components/preprocess_production_data` directory). \n",
        "\n",
        "You can use both to investigate how you could bring your own data, and (if you know how to register components) set up a monitor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next steps\n",
        "\n",
        "In the next notebook we'll learn more about Data Drift. Continue with the next notebook to **Create Synthentic Data** and then gather inference data that triggers data drift detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "bd2f20a2ae7e9e927b52643942994f3aab4e8a0fff0d99512b6bf37211656242"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
